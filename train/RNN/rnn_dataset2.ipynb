{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c1e5b7d-3929-4196-88a5-78f0b51ccb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fake News Detection using RNN - Jupyter Notebook\n",
    "\n",
    "# First, let's import the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "393a5d9e-64a0-4ea1-b111-5b68e7cb8cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text\n",
       "0           0  Donald Trump just couldn t wish all Americans ...\n",
       "1           1  House Intelligence Committee Chairman Devin Nu...\n",
       "2           2  On Friday, it was revealed that former Milwauk...\n",
       "3           3  On Christmas day, Donald Trump announced that ...\n",
       "4           4  Pope Francis used his annual Christmas Day mes..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "# load csv files to dataframes\n",
    "df_fake=pd.read_csv('../datasets/dataset2/archive/DataSet_Misinfo_FAKE.csv')\n",
    "df_real=pd.read_csv('../datasets/dataset2/archive/DataSet_Misinfo_TRUE.csv')\n",
    "df_fake.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f3b6403-9fd9-4a30-b61e-69c51772382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the necessary columns \n",
    "df_fake=df_fake.iloc[:,1:2]\n",
    "df_real=df_real.iloc[:,1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74d290c0-d9a6-4ac8-b077-41e3686cdb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text  class\n",
      "0      Donald Trump just couldn t wish all Americans ...      0\n",
      "1      House Intelligence Committee Chairman Devin Nu...      0\n",
      "2      On Friday, it was revealed that former Milwauk...      0\n",
      "3      On Christmas day, Donald Trump announced that ...      0\n",
      "4      Pope Francis used his annual Christmas Day mes...      0\n",
      "...                                                  ...    ...\n",
      "43637  The USA wants to divide Syria.\\r\\n\\r\\nGreat Br...      0\n",
      "43638  The Ukrainian coup d'etat cost the US nothing ...      0\n",
      "43639  The European Parliament falsifies history by d...      0\n",
      "43640  The European Parliament falsifies history by d...      0\n",
      "43641  A leading FSB officer, Segey Beseda, said duri...      0\n",
      "\n",
      "[43642 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# label the class values\n",
    "df_fake['class']=0\n",
    "df_real['class']=1\n",
    "print(df_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3d78d5d-bc98-4690-b9fe-924cd4a91a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78617, 2)\n",
      "78617\n"
     ]
    }
   ],
   "source": [
    "# concatenate 2 dataframes\n",
    "df=pd.concat([df_fake, df_real], ignore_index=True, sort=False )\n",
    "\n",
    "print(df.shape)\n",
    "print(len(df))\n",
    "#merge \"title\" and \"text\" values in same column\n",
    "df.insert(0,column=\"title_text\", value=df['text'] + \" \" + df['text'])\n",
    "\n",
    "#remove previous columns that are merged\n",
    "df.drop (['text', 'text'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35930ac0-a299-45e2-94a9-5929b26980de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          title_text  class\n",
       "0  Donald Trump just couldn t wish all Americans ...      0\n",
       "1  House Intelligence Committee Chairman Devin Nu...      0\n",
       "2  On Friday, it was revealed that former Milwauk...      0\n",
       "3  On Christmas day, Donald Trump announced that ...      0\n",
       "4  Pope Francis used his annual Christmas Day mes...      0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13a080be-195e-4721-831d-ed4103e75b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preprocess the data\n",
    "X = df.title_text.values\n",
    "y = df['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2e1c060-77a1-4308-af05-678fde80c2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf2b7422-2f20-4a0e-b92d-56c42e37cb50",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Tokenize text\u001b[39;00m\n\u001b[1;32m      2\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m Tokenizer()\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_on_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhere\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m X \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mtexts_to_sequences(X)\n",
      "File \u001b[0;32m~/ws/Now/fakeNews/env/lib/python3.12/site-packages/keras/src/legacy/preprocessing/text.py:133\u001b[0m, in \u001b[0;36mTokenizer.fit_on_texts\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manalyzer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 133\u001b[0m         seq \u001b[38;5;241m=\u001b[39m \u001b[43mtext_to_word_sequence\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m            \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m         seq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manalyzer(text)\n",
      "File \u001b[0;32m~/ws/Now/fakeNews/env/lib/python3.12/site-packages/keras/src/legacy/preprocessing/text.py:22\u001b[0m, in \u001b[0;36mtext_to_word_sequence\u001b[0;34m(input_text, filters, lower, split)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"DEPRECATED.\"\"\"\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lower:\n\u001b[0;32m---> 22\u001b[0m     input_text \u001b[38;5;241m=\u001b[39m \u001b[43minput_text\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m()\n\u001b[1;32m     24\u001b[0m translate_dict \u001b[38;5;241m=\u001b[39m {c: split \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m filters}\n\u001b[1;32m     25\u001b[0m translate_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m\u001b[38;5;241m.\u001b[39mmaketrans(translate_dict)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "# Tokenize text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X)\n",
    "print(\"here\")\n",
    "X = tokenizer.texts_to_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a67a0f-d151-47c1-a036-18b7c59ab56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences\n",
    "max_length = 100\n",
    "X = pad_sequences(X, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b93c08-730b-4b2c-9101-a1fc61802439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfdbe84-f35d-496f-bc43-8e7999ef0a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, 100, input_length=max_length),\n",
    "    LSTM(128),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.build(input_shape=(None, max_length))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5b8c2b-9a95-422e-b234-e8a85794dc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff73d2d4-4f22-43c0-b760-dc3938fbba42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=5, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3acd5c7-db09-4d7e-9efe-f3e247027f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bffe87-05a0-466c-aed9-e358ce5e8fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make predictions\n",
    "def predict_fake_news(text):\n",
    "    sequence = tokenizer.texts_to_sequences([text])\n",
    "    padded = pad_sequences(sequence, maxlen=max_length)\n",
    "    prediction = model.predict(padded)[0][0]\n",
    "    return \"Fake\" if prediction > 0.5 else \"Real\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a41a5a-7ba7-442f-8f13-dcd79585d50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model with some example texts\n",
    "example_texts = [\n",
    "    \"Breaking: Scientists discover new planet capable of supporting life!\",\n",
    "    \"Local community comes together to clean up neighborhood park\",\n",
    "    \"Shocking: Celebrity secretly a robot, inside sources reveal\",\n",
    "    \"New study shows benefits of regular exercise on mental health\"\n",
    "]\n",
    "\n",
    "for text in example_texts:\n",
    "    prediction = predict_fake_news(text)\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Prediction: {prediction}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b88557-4e46-47e4-b88a-95fe04dc3b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive prediction\n",
    "while True:\n",
    "    user_input = input(\"Enter a news headline (or 'quit' to exit): \")\n",
    "    if user_input.lower() == 'quit':\n",
    "        break\n",
    "    prediction = predict_fake_news(user_input)\n",
    "    print(f\"Prediction: {prediction}\\n\")\n",
    "\n",
    "print(\"Thank you for using the Fake News Detector!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823159ba-1d00-40ce-85e5-05ad941aa5eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
