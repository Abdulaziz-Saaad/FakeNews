{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d5cbc39-79da-442b-a6ea-9bcfcf1c1bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c68715b4-53c6-4a5a-806f-089fffc3ed62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roman/ws/Now/fakeNews/env/lib/python3.12/site-packages/datasets/load.py:1491: FutureWarning: The repository for ucsbnlp/liar contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/ucsbnlp/liar\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "061aaec334ea427bab6cbaf45d9e801f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/10269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# dataset = load_dataset(\"ucsbnlp/liar\")\n",
    "dataset = load_dataset(\"ucsbnlp/liar\", split=\"train\")\n",
    "dataset.save_to_disk('liar_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3114f01-1c2e-441c-aa49-18a0eae463d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               id        label  \\\n",
      "0       2635.json        false   \n",
      "1      10540.json    half-true   \n",
      "2        324.json  mostly-true   \n",
      "3       1123.json        false   \n",
      "4       9028.json    half-true   \n",
      "...           ...          ...   \n",
      "10235   5473.json  mostly-true   \n",
      "10236   3408.json  mostly-true   \n",
      "10237   3959.json    half-true   \n",
      "10238   2253.json        false   \n",
      "10239   1155.json   pants-fire   \n",
      "\n",
      "                                               statement  \\\n",
      "0      Says the Annies List political group supports ...   \n",
      "1      When did the decline of coal start? It started...   \n",
      "2      Hillary Clinton agrees with John McCain \"by vo...   \n",
      "3      Health care reform legislation is likely to ma...   \n",
      "4      The economic turnaround started at the end of ...   \n",
      "...                                                  ...   \n",
      "10235  There are a larger number of shark attacks in ...   \n",
      "10236  Democrats have now become the party of the [At...   \n",
      "10237  Says an alternative to Social Security that op...   \n",
      "10238  On lifting the U.S. Cuban embargo and allowing...   \n",
      "10239  The Department of Veterans Affairs has a manua...   \n",
      "\n",
      "                                  subject         speaker  \\\n",
      "0                                abortion    dwayne-bohac   \n",
      "1      energy,history,job-accomplishments  scott-surovell   \n",
      "2                          foreign-policy    barack-obama   \n",
      "3                             health-care    blog-posting   \n",
      "4                            economy,jobs   charlie-crist   \n",
      "...                                   ...             ...   \n",
      "10235                   animals,elections    aclu-florida   \n",
      "10236                           elections     alan-powell   \n",
      "10237          retirement,social-security     herman-cain   \n",
      "10238              florida,foreign-policy     jeff-greene   \n",
      "10239                health-care,veterans  michael-steele   \n",
      "\n",
      "                                           job_title     state       party  \\\n",
      "0                               State representative     Texas  republican   \n",
      "1                                     State delegate  Virginia    democrat   \n",
      "2                                          President  Illinois    democrat   \n",
      "3                                                NaN       NaN        none   \n",
      "4                                                NaN   Florida    democrat   \n",
      "...                                              ...       ...         ...   \n",
      "10235                                            NaN   Florida        none   \n",
      "10236                                            NaN   Georgia  republican   \n",
      "10237                                            NaN   Georgia  republican   \n",
      "10238                                            NaN   Florida    democrat   \n",
      "10239  chairman of the Republican National Committee  Maryland  republican   \n",
      "\n",
      "       barely_true_counts  false_counts  half_true_counts  mostly_true_counts  \\\n",
      "0                     0.0           1.0               0.0                 0.0   \n",
      "1                     0.0           0.0               1.0                 1.0   \n",
      "2                    70.0          71.0             160.0               163.0   \n",
      "3                     7.0          19.0               3.0                 5.0   \n",
      "4                    15.0           9.0              20.0                19.0   \n",
      "...                   ...           ...               ...                 ...   \n",
      "10235                 0.0           1.0               1.0                 1.0   \n",
      "10236                 0.0           0.0               0.0                 1.0   \n",
      "10237                 4.0          11.0               5.0                 3.0   \n",
      "10238                 3.0           1.0               3.0                 0.0   \n",
      "10239                 0.0           1.0               1.0                 0.0   \n",
      "\n",
      "       pants_on_fire_counts                                            context  \n",
      "0                       0.0                                           a mailer  \n",
      "1                       0.0                                    a floor speech.  \n",
      "2                       9.0                                             Denver  \n",
      "3                      44.0                                     a news release  \n",
      "4                       2.0                                an interview on CNN  \n",
      "...                     ...                                                ...  \n",
      "10235                   0.0                  interview on \"The Colbert Report\"  \n",
      "10236                   0.0                                       an interview  \n",
      "10237                   3.0                   a Republican presidential debate  \n",
      "10238                   0.0  a televised debate on Miami's WPLG-10 against ...  \n",
      "10239                   2.0                               a Fox News interview  \n",
      "\n",
      "[10240 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('./liar_dataset/train.tsv', delimiter='\\t', header=None)\n",
    "df.columns = ['id', 'label', 'statement', 'subject', 'speaker', 'job_title', \n",
    "              'state', 'party', 'barely_true_counts', 'false_counts', \n",
    "              'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts', 'context']\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bfb6d24-0878-4955-b411-f2e288b22b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       label                                          statement\n",
      "0          0  Says the Annies List political group supports ...\n",
      "1          1  When did the decline of coal start? It started...\n",
      "2          1  Hillary Clinton agrees with John McCain \"by vo...\n",
      "3          0  Health care reform legislation is likely to ma...\n",
      "4          1  The economic turnaround started at the end of ...\n",
      "...      ...                                                ...\n",
      "10235      1  There are a larger number of shark attacks in ...\n",
      "10236      1  Democrats have now become the party of the [At...\n",
      "10237      1  Says an alternative to Social Security that op...\n",
      "10238      0  On lifting the U.S. Cuban embargo and allowing...\n",
      "10239      0  The Department of Veterans Affairs has a manua...\n",
      "\n",
      "[10240 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Select necessary columns\n",
    "df = df[['label', 'statement']]\n",
    "\n",
    "# Map labels to binary classification\n",
    "df['label'] = df['label'].map({\n",
    "    'true': 1, \n",
    "    'mostly-true': 1, \n",
    "    'half-true': 1, \n",
    "    'barely-true': 0, \n",
    "    'false': 0, \n",
    "    'pants-fire': 0\n",
    "})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9497f2b7-c080-43e2-88ab-4f7b8b5d9e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550     We are now, for the first time ever, energy in...\n",
      "7231    Were not engaged in nation-building in Afghani...\n",
      "2515    Because of President Barack Obamas failure to ...\n",
      "4466    New carbon regulations will increase electric ...\n",
      "211     Obamacare is the biggest tax increase in Ameri...\n",
      "                              ...                        \n",
      "5734    When I took office, the deficit was nearly 10 ...\n",
      "5191                      On the mosque near ground zero.\n",
      "5390    Louie Gohmert of Texas blamed the mass shootin...\n",
      "860     The Governor did not consult members of his ow...\n",
      "7270    A telecom bill could keep the State Corporatio...\n",
      "Name: statement, Length: 8192, dtype: object 3842     Polling shows that nearly 74 percent of Nation...\n",
      "6480         I left the city with $43 million in the bank.\n",
      "4521     Says she couldn't take stimulus money because ...\n",
      "4026     The United States is the only industrialized c...\n",
      "10111    The Health Care and Education Reconciliation A...\n",
      "                               ...                        \n",
      "5474     Loretta Lynch, the new nominee for attorney ge...\n",
      "3057     Right now the Tea Party polls higher than the ...\n",
      "3123     Says Russ Feingold broke his 1992 promise to a...\n",
      "9148     This governor has given us continual balanced ...\n",
      "6301     Hillary Clinton \"has the only health care plan...\n",
      "Name: statement, Length: 2048, dtype: object 550     0\n",
      "7231    1\n",
      "2515    0\n",
      "4466    0\n",
      "211     0\n",
      "       ..\n",
      "5734    1\n",
      "5191    1\n",
      "5390    0\n",
      "860     0\n",
      "7270    0\n",
      "Name: label, Length: 8192, dtype: int64 3842     1\n",
      "6480     0\n",
      "4521     0\n",
      "4026     1\n",
      "10111    0\n",
      "        ..\n",
      "5474     0\n",
      "3057     0\n",
      "3123     1\n",
      "9148     1\n",
      "6301     1\n",
      "Name: label, Length: 2048, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['statement'], df['label'], test_size=0.2, random_state=42)\n",
    "print(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "127ea0fd-38f0-4bb8-b956-c9e77803c328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0b763e2-5c18-4854-8d28-4806232f7b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the training data\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1566c144-4b56-4cfa-a1cb-ae9cca909b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 320)\t0.16853232521597145\n",
      "  (0, 438)\t0.32247722841075743\n",
      "  (0, 488)\t0.26297772295211475\n",
      "  (0, 821)\t0.2869991588431989\n",
      "  (0, 1689)\t0.10741925220949278\n",
      "  (0, 1879)\t0.22171723590846704\n",
      "  (0, 2645)\t0.23337345106799107\n",
      "  (0, 2815)\t0.20074456763133275\n",
      "  (0, 2825)\t0.2050480889229645\n",
      "  (0, 2927)\t0.07945473265228409\n",
      "  (0, 3179)\t0.1336593237833107\n",
      "  (0, 3285)\t0.33593078688508177\n",
      "  (0, 3760)\t0.3044049846117915\n",
      "  (0, 3818)\t0.32247722841075743\n",
      "  (0, 3884)\t0.24719780808431074\n",
      "  (0, 4023)\t0.2559032978761419\n",
      "  (0, 4269)\t0.21270321718245078\n",
      "  (0, 4416)\t0.11427406975532184\n",
      "  (1, 118)\t0.5059616635223685\n",
      "  (1, 506)\t0.4826503671556121\n",
      "  (1, 859)\t0.34974615607953935\n",
      "  (1, 2071)\t0.13340486995502887\n",
      "  (1, 2435)\t0.4268354590764318\n",
      "  (1, 2689)\t0.2822180759174692\n",
      "  (1, 4418)\t0.20987542348952018\n",
      "  :\t:\n",
      "  (2045, 4418)\t0.06577700292344864\n",
      "  (2045, 4479)\t0.08977455349680387\n",
      "  (2045, 4916)\t0.20274761682503892\n",
      "  (2046, 499)\t0.39415847155646533\n",
      "  (2046, 679)\t0.4032896825109492\n",
      "  (2046, 1804)\t0.35959394504831593\n",
      "  (2046, 1835)\t0.28363523616621744\n",
      "  (2046, 1912)\t0.1740791877119966\n",
      "  (2046, 3567)\t0.35382626777543835\n",
      "  (2046, 4350)\t0.24730415110383805\n",
      "  (2046, 4441)\t0.230832716930186\n",
      "  (2046, 4688)\t0.32377132972229966\n",
      "  (2046, 4926)\t0.3122054245187605\n",
      "  (2047, 343)\t0.30321283470792787\n",
      "  (2047, 750)\t0.2579786618154109\n",
      "  (2047, 882)\t0.2996163114503058\n",
      "  (2047, 1064)\t0.522549644903198\n",
      "  (2047, 1504)\t0.27577489261778443\n",
      "  (2047, 1912)\t0.1969774106826149\n",
      "  (2047, 1929)\t0.24806051753714922\n",
      "  (2047, 1964)\t0.3142015095160963\n",
      "  (2047, 2967)\t0.27216526223373383\n",
      "  (2047, 3243)\t0.2953148373315659\n",
      "  (2047, 4416)\t0.18169950949549168\n",
      "  (2047, 4418)\t0.09629603270316578\n"
     ]
    }
   ],
   "source": [
    "# Transform the test data\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "print(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8476e2d-22f4-4823-8798-098fea0497bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_tfidf shape: (8192, 5000)\n",
      "y_train shape: (8192,)\n",
      "Data types: <class 'scipy.sparse._csr.csr_matrix'> <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# Debug: Check shapes and types\n",
    "print(\"X_train_tfidf shape:\", X_train_tfidf.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"Data types:\", type(X_train_tfidf), type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "083d3c06-94ca-41ed-849a-7a73f4908642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Logistic Regression\n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a861ae1-9b2a-4227-ae28-3c55d7655022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained successfully.\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "try:\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    print(\"Model trained successfully.\")\n",
    "except ValueError as e:\n",
    "    print(\"Error during model fitting:\", e)\n",
    "    print(\"Ensure X_train_tfidf and y_train are compatible and have correct shapes.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "161f95b6-61a7-4863-8cb5-6b67278d7870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8533669e-1631-4a1c-99ac-678e99198332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6162109375\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.47      0.52       888\n",
      "           1       0.64      0.73      0.68      1160\n",
      "\n",
      "    accuracy                           0.62      2048\n",
      "   macro avg       0.61      0.60      0.60      2048\n",
      "weighted avg       0.61      0.62      0.61      2048\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print Accuracy and Classification Report\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b71e0784-9aaf-4db5-841a-54cf7cc60913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vectorizer.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model and vectorizer\n",
    "joblib.dump(model, 'model.pkl')\n",
    "joblib.dump(vectorizer, 'vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c483555-5703-474b-870c-59e81fcec640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2199)\t0.8825229163216437\n",
      "  (0, 4418)\t0.4702693931855879\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "X = vectorizer.transform([\"the sky is bule\"])\n",
    "prediction = model.predict(X)\n",
    "print(X)\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
